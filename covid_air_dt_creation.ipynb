{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run conf_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                  # for DataFrames\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "key = 'd1dca54adaf64d419fa1a6a6efef0e43'\n",
    "geocoder = OpenCageGeocode(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build functions\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "\n",
    "def get_nearest(src_points, candidates, k_neighbors=10):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='haversine')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "    radius = distances[9]\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    # note: for the second closest points, you would take index 1, etc.\n",
    "    closest0 = indices[0]    \n",
    "    closest1 = indices[1]\n",
    "    closest2 = indices[2]\n",
    "    closest3 = indices[3]\n",
    "    closest4 = indices[4]\n",
    "    closest5 = indices[5]\n",
    "    closest6 = indices[6]\n",
    "    closest7 = indices[7]\n",
    "    closest8 = indices[8]\n",
    "    closest9 = indices[9]\n",
    "    #return (closest9)\n",
    "    # Return indices and distances\n",
    "    return (radius, closest0, closest1,closest2,closest3,closest4,closest5,closest6,closest7,closest8,closest9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(left_gdf, right_gdf, return_dist=False):\n",
    "    \"\"\"\n",
    "    For each point in left_gdf, find closest point in right GeoDataFrame and return them.\n",
    "\n",
    "    NOTICE: Assumes that the input Points are in WGS84 projection (lat/lon).\n",
    "    \"\"\"\n",
    "\n",
    "    left_geom_col = left_gdf.geometry.name\n",
    "    right_geom_col = right_gdf.geometry.name\n",
    "\n",
    "    # Ensure that index in right gdf is formed of sequential numbers\n",
    "    right = right_gdf.copy().reset_index(drop=True)\n",
    "\n",
    "    # Parse coordinates from points and insert them into a numpy array as RADIANS\n",
    "    left_radians = np.array(left_gdf[left_geom_col].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
    "    right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
    "\n",
    "    # Find the nearest points\n",
    "    # -----------------------\n",
    "    # closest ==> index in right_gdf that corresponds to the closest point\n",
    "    # dist ==> distance between the nearest neighbors (in meters)\n",
    "\n",
    "    radius, closest, closest1,closest2,closest3,closest4,closest5,closest6,closest7,closest8,closest9 = get_nearest(src_points=left_radians, candidates=right_radians)\n",
    "    #closest = get_nearest(src_points=left_radians, candidates=right_radians)\n",
    "    # Return points from right GeoDataFrame that are closest to points in left GeoDataFrame\n",
    "    closest_points = right.loc[closest].reset_index(drop=True)\n",
    "    closest_points1 = right.loc[closest1].reset_index(drop=True)\n",
    "    closest_points2 = right.loc[closest2].reset_index(drop=True)\n",
    "    closest_points3 = right.loc[closest3].reset_index(drop=True)\n",
    "    closest_points4 = right.loc[closest4].reset_index(drop=True)\n",
    "    closest_points5 = right.loc[closest5].reset_index(drop=True)\n",
    "    closest_points6 = right.loc[closest6].reset_index(drop=True)\n",
    "    closest_points7 = right.loc[closest7].reset_index(drop=True)\n",
    "    closest_points8 = right.loc[closest8].reset_index(drop=True)\n",
    "    closest_points9 = right.loc[closest9].reset_index(drop=True)\n",
    "    \n",
    "    df_to_agg = pd.concat([closest_points, closest_points1,\n",
    "                          closest_points2,\n",
    "                          closest_points3,\n",
    "                          closest_points4,\n",
    "                          closest_points5,\n",
    "                          closest_points6,\n",
    "                          closest_points7,\n",
    "                          closest_points8,\n",
    "                          closest_points9])\n",
    "    df_to_agg = df_to_agg.drop(columns = ['geometry'])\n",
    "    df_agg = df_to_agg.groupby(df_to_agg.index).agg('mean')\n",
    "    \n",
    "    # Add distance if requested\n",
    "    if return_dist:\n",
    "        # Convert to meters from radians\n",
    "        earth_radius = 6371000  # meters\n",
    "        df_agg['radius'] = radius * earth_radius\n",
    "\n",
    "    merged_gpd = left_gdf.join(df_agg)\n",
    "    return merged_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Code</th>\n",
       "      <th>Mean_ann_earnings</th>\n",
       "      <th>median_age_2018</th>\n",
       "      <th>Name</th>\n",
       "      <th>2018 people per sq. km</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>25985.0</td>\n",
       "      <td>41.8</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>E06000002</td>\n",
       "      <td>22878.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2608</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E06000003</td>\n",
       "      <td>23236.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>558</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E06000004</td>\n",
       "      <td>26622.0</td>\n",
       "      <td>40.4</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>962</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>E06000005</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>540</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>331</td>\n",
       "      <td>W06000020</td>\n",
       "      <td>25755.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Torfaen</td>\n",
       "      <td>740</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>332</td>\n",
       "      <td>W06000021</td>\n",
       "      <td>32558.0</td>\n",
       "      <td>48.6</td>\n",
       "      <td>Monmouthshire</td>\n",
       "      <td>111</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>333</td>\n",
       "      <td>W06000022</td>\n",
       "      <td>24974.0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>Newport</td>\n",
       "      <td>805</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>318</td>\n",
       "      <td>W06000023</td>\n",
       "      <td>22421.0</td>\n",
       "      <td>49.9</td>\n",
       "      <td>Powys</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>328</td>\n",
       "      <td>W06000024</td>\n",
       "      <td>23889.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>Merthyr Tydfil</td>\n",
       "      <td>540</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Code  Mean_ann_earnings  median_age_2018  \\\n",
       "0             1  E06000001            25985.0             41.8   \n",
       "1             2  E06000002            22878.0             36.2   \n",
       "2             3  E06000003            23236.0             45.0   \n",
       "3             4  E06000004            26622.0             40.4   \n",
       "4             0  E06000005            26908.0             43.1   \n",
       "..          ...        ...                ...              ...   \n",
       "329         331  W06000020            25755.0             42.4   \n",
       "330         332  W06000021            32558.0             48.6   \n",
       "331         333  W06000022            24974.0             38.8   \n",
       "332         318  W06000023            22421.0             49.9   \n",
       "333         328  W06000024            23889.0             40.5   \n",
       "\n",
       "                     Name  2018 people per sq. km  deaths  \n",
       "0              Hartlepool                     997      20  \n",
       "1           Middlesbrough                    2608      60  \n",
       "2    Redcar and Cleveland                     558      26  \n",
       "3        Stockton-on-Tees                     962      26  \n",
       "4              Darlington                     540      14  \n",
       "..                    ...                     ...     ...  \n",
       "329               Torfaen                     740      33  \n",
       "330         Monmouthshire                     111      25  \n",
       "331               Newport                     805      61  \n",
       "332                 Powys                      26      18  \n",
       "333        Merthyr Tydfil                     540      15  \n",
       "\n",
       "[334 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#covid_dt = pd.read_csv(\"%s/merged_covid_cov_dt_LA.csv\" %path_output)\n",
    "covid_dt = pd.read_csv(\"%s/merged_covid_dt.csv\" %path_out)\n",
    "covid_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to get lat long\n",
    "list_lat = []   # create empty lists\n",
    "\n",
    "list_lon = []\n",
    "\n",
    "for index, row in covid_dt.iterrows(): # iterate over rows in dataframe\n",
    "    \n",
    "    query = row['Name']  + ', England, UK'\n",
    "\n",
    "    results = geocoder.geocode(query)   \n",
    "    lat = results[0]['geometry']['lat']\n",
    "    lon = results[0]['geometry']['lng']\n",
    "\n",
    "    list_lat.append(lat)\n",
    "    list_lon.append(lon)\n",
    "\n",
    "# create new columns from lists    \n",
    "\n",
    "covid_dt['lat'] = list_lat   \n",
    "\n",
    "covid_dt['lon'] = list_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Code</th>\n",
       "      <th>Mean_ann_earnings</th>\n",
       "      <th>median_age_2018</th>\n",
       "      <th>Name</th>\n",
       "      <th>2018 people per sq. km</th>\n",
       "      <th>deaths</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>25985.0</td>\n",
       "      <td>41.8</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "      <td>54.685728</td>\n",
       "      <td>-1.209370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>E06000002</td>\n",
       "      <td>22878.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2608</td>\n",
       "      <td>60</td>\n",
       "      <td>54.576042</td>\n",
       "      <td>-1.234405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E06000003</td>\n",
       "      <td>23236.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>558</td>\n",
       "      <td>26</td>\n",
       "      <td>54.567906</td>\n",
       "      <td>-1.005496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E06000004</td>\n",
       "      <td>26622.0</td>\n",
       "      <td>40.4</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>962</td>\n",
       "      <td>26</td>\n",
       "      <td>54.564094</td>\n",
       "      <td>-1.312916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>E06000005</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>540</td>\n",
       "      <td>14</td>\n",
       "      <td>54.524208</td>\n",
       "      <td>-1.555581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Code  Mean_ann_earnings  median_age_2018  \\\n",
       "0           1  E06000001            25985.0             41.8   \n",
       "1           2  E06000002            22878.0             36.2   \n",
       "2           3  E06000003            23236.0             45.0   \n",
       "3           4  E06000004            26622.0             40.4   \n",
       "4           0  E06000005            26908.0             43.1   \n",
       "\n",
       "                   Name  2018 people per sq. km  deaths        lat       lon  \n",
       "0            Hartlepool                     997      20  54.685728 -1.209370  \n",
       "1         Middlesbrough                    2608      60  54.576042 -1.234405  \n",
       "2  Redcar and Cleveland                     558      26  54.567906 -1.005496  \n",
       "3      Stockton-on-Tees                     962      26  54.564094 -1.312916  \n",
       "4            Darlington                     540      14  54.524208 -1.555581  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dt.to_csv(\"data_out/merged_covid_cov_dt_LA_LL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, merge the covid dataset to the modelled background pollution dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_df = pd.read_csv(\"%s/processed_pm25_lonlat.csv\" %path, usecols=['pm25_lon','pm25_lat','pm25_val'])\n",
    "no2_df = pd.read_csv('%s/processed_no2_lonlat.csv' %path, usecols = ['no2_lon','no2_lat','no2_val'])\n",
    "o3_df = pd.read_csv('%s/processed_o3_lonlat.csv' %path, usecols = ['o3_lon','o3_lat','o3_val'])\n",
    "pm10_df = pd.read_csv('%s/processed_pm10_lonlat.csv' %path, usecols = ['pm10_lon','pm10_lat','pm10_val'])\n",
    "so2_df = pd.read_csv('%s/processed_so2_lonlat.csv' %path, usecols = ['so2_lon','so2_lat','so2_val'])\n",
    "nox_df = pd.read_csv('%s/processed_nox_lonlat.csv' %path, usecols = ['nox_lon','nox_lat','nox_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covid_dt = pd.read_csv('%/merged_covid_cov_dt_LA_LL.csv' %path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-313bc4591fab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conda install geopandas'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_gpd_air_dt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     '''\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpd\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "def to_gpd_air_dt(input_df):\n",
    "    '''\n",
    "    from pd to gpd \n",
    "    the input datasets must be lon, lat, val\n",
    "    '''\n",
    "    out_gpd = gpd.GeoDataFrame(\n",
    "    input_df, geometry=gpd.points_from_xy(input_df.iloc[:,0], input_df.iloc[:,1]))\n",
    "    return(out_gpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_gpd = to_gpd_air_dt(pm25_df)\n",
    "no2_gpd = to_gpd_air_dt(no2_df)\n",
    "o3_gpd = to_gpd_air_dt(o3_df)\n",
    "pm10_gpd = to_gpd_air_dt(pm10_df)\n",
    "so2_gpd = to_gpd_air_dt(so2_df)\n",
    "nox_gpd = to_gpd_air_dt(nox_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_covid = nearest_neighbor(covid_gpd[['Code','geometry']], pm25_gpd, return_dist=True)\n",
    "no2_covid = nearest_neighbor(covid_gpd[['Code','geometry']], no2_gpd, return_dist=True)\n",
    "o3_covid = nearest_neighbor(covid_gpd[['Code','geometry']], o3_gpd, return_dist=True)\n",
    "pm10_covid = nearest_neighbor(covid_gpd[['Code','geometry']], pm10_gpd, return_dist=True)\n",
    "so2_covid = nearest_neighbor(covid_gpd[['Code','geometry']], so2_gpd, return_dist=True)\n",
    "nox_covid = nearest_neighbor(covid_gpd[['Code','geometry']], nox_gpd, return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now i need to match the df above\n",
    "pm25_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is now obsolete\n",
    "# pm25_covid = covid_gpd[['Code','geometry']].join(pm25_covid)\n",
    "# no2_covid = covid_gpd[['Code','geometry']].join(no2_covid)\n",
    "# o3_covid = covid_gpd[['Code','geometry']].join(o3_covid)\n",
    "# pm10_covid = covid_gpd[['Code','geometry']].join(pm10_covid)\n",
    "# so2_covid = covid_gpd[['Code','geometry']].join(so2_covid)\n",
    "# nox_covid = covid_gpd[['Code','geometry']].join(nox_covid)\n",
    "# so2_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge everything togerther and export \n",
    "\n",
    "covid_Allair_poll_df = pd.merge(covid_gpd.drop(columns=['geometry','Name']), pm25_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, no2_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, o3_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, pm10_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, so2_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, nox_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "\n",
    "covid_Allair_poll_df.to_csv(\"data_output_v4/merged_covidAir_cov_dt_LA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will overwrite on the same variables for simplicity\n",
    "covid_dt = pd.read_csv('data_output_v4/merged_covid_cov_dt_LA_LL.csv')\n",
    "# AP5Y_dt = pd.read_csv('data_output_v4/5Yaverage_AP_PCMdata_na.csv')\n",
    "pm25_df = pd.read_csv(\"data_output_v4/processed_allAP_lonlat.csv\", usecols=['lon','lat','pm25_5yAvg'])\n",
    "no2_df = pd.read_csv('data_output_v4/processed_allAP_lonlat.csv', usecols = ['lon','lat','no2_5yAvg'])\n",
    "o3_df = pd.read_csv('data_output_v4/processed_allAP_lonlat.csv', usecols = ['lon','lat','o3_5yAvg'])\n",
    "pm10_df = pd.read_csv('data_output_v4/processed_allAP_lonlat.csv', usecols = ['lon','lat','pm10_5yAvg'])\n",
    "# so2_df = pd.read_csv('data_output_v4/processed_allAP_lonlat.csv', usecols = ['lon','lat','so2_val'])\n",
    "nox_df = pd.read_csv('data_output_v4/processed_allAP_lonlat.csv', usecols = ['lon','lat','nox_5yAvg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "def to_gpd_air_dt(input_df):\n",
    "    '''\n",
    "    from pd to gpd \n",
    "    the input datasets must be lon, lat, val\n",
    "    '''\n",
    "    out_gpd = gpd.GeoDataFrame(\n",
    "    input_df, geometry=gpd.points_from_xy(input_df.loc[:,'lon'], input_df.loc[:,'lat']))\n",
    "    return(out_gpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate data type\n",
    "pm25_gpd = to_gpd_air_dt(pm25_df)\n",
    "no2_gpd = to_gpd_air_dt(no2_df)\n",
    "o3_gpd = to_gpd_air_dt(o3_df)\n",
    "pm10_gpd = to_gpd_air_dt(pm10_df)\n",
    "# so2_gpd = to_gpd_air_dt(so2_df)\n",
    "nox_gpd = to_gpd_air_dt(nox_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dt = pd.read_csv('data_v4/merged_covid_cov_dt_LA_LL.csv')\n",
    "covid_gpd = to_gpd_air_dt(covid_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculations here \n",
    "pm25_covid = nearest_neighbor(covid_gpd[['Code','geometry']], pm25_gpd, return_dist=True)\n",
    "no2_covid = nearest_neighbor(covid_gpd[['Code','geometry']], no2_gpd, return_dist=True)\n",
    "o3_covid = nearest_neighbor(covid_gpd[['Code','geometry']], o3_gpd, return_dist=True)\n",
    "pm10_covid = nearest_neighbor(covid_gpd[['Code','geometry']], pm10_gpd, return_dist=True)\n",
    "# so2_covid = nearest_neighbor(covid_gpd[['Code','geometry']], so2_gpd, return_dist=True)\n",
    "nox_covid = nearest_neighbor(covid_gpd[['Code','geometry']], nox_gpd, return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge everything togerther and export \n",
    "\n",
    "covid_Allair_poll_df = pd.merge(covid_gpd.drop(columns=['geometry','Name','lon','lat']), \n",
    "                                pm25_covid.drop(columns=['geometry','radius','lon','lat','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, \n",
    "                                no2_covid.drop(columns=['geometry','radius','lon','lat','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, \n",
    "                                o3_covid.drop(columns=['geometry','radius','lon','lat','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, \n",
    "                                pm10_covid.drop(columns=['geometry','radius','lon','lat','radius']), on='Code')\n",
    "# covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, so2_covid.drop(columns=['geometry','radius']), on='Code')\n",
    "covid_Allair_poll_df = pd.merge(covid_Allair_poll_df, \n",
    "                                nox_covid.drop(columns=['geometry','radius','lon','lat','radius']), on='Code')\n",
    "\n",
    "covid_Allair_poll_df = covid_Allair_poll_df.drop(columns=['Unnamed: 0'])\n",
    "covid_Allair_poll_df.to_csv(\"data_output_v4/merged_covidAir_cov_LA_5YA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_Allair_poll_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
